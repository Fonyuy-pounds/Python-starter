{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "gpuType": "V28",
      "authorship_tag": "ABX9TyMlPPSlSDggC7doCHi+BhYe",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fonyuy-pounds/Python-starter/blob/master/TextCaption.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3FEAANMweCBs"
      },
      "outputs": [],
      "source": [
        "!pip install gradio openai-whisper torchaudio pydub ffmpeg-python\n",
        "!apt-get install ffmpeg"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython import get_ipython\n",
        "from IPython.display import display\n",
        "# %%\n",
        "!pip install gradio openai-whisper torchaudio pydub ffmpeg-python\n",
        "!apt-get install ffmpeg\n",
        "# %%\n",
        "from IPython.display import display\n",
        "import gradio as gr\n",
        "import whisper\n",
        "import torch\n",
        "import tempfile\n",
        "from pydub import AudioSegment\n",
        "import os\n",
        "from typing import Optional\n",
        "\n",
        "# Install required packages\n",
        "get_ipython().system('pip install gradio openai-whisper torchaudio pydub ffmpeg-python')\n",
        "get_ipython().system('apt-get install ffmpeg')\n",
        "\n",
        "# Check for GPU availability\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Load the Whisper model\n",
        "model = whisper.load_model(\"medium\", device=device)\n",
        "\n",
        "def transcribe_audio(audio_path: str, language: Optional[str] = None) -> str:\n",
        "    try:\n",
        "        audio = whisper.load_audio(audio_path)\n",
        "        audio = whisper.pad_or_trim(audio)\n",
        "        mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
        "\n",
        "        if language is None:\n",
        "            _, probs = model.detect_language(mel)\n",
        "            language = max(probs, key=probs.get)\n",
        "            print(f\"Detected language: {language}\")\n",
        "\n",
        "        options = whisper.DecodingOptions(language=language, fp16=False)\n",
        "        result = whisper.decode(model, mel, options)\n",
        "        return result.text\n",
        "    except Exception as e:\n",
        "        return f\"Error during transcription: {str(e)}\"\n",
        "\n",
        "def process_uploaded_file(file, language):\n",
        "    try:\n",
        "        with tempfile.NamedTemporaryFile(suffix=os.path.splitext(file.name)[1], delete=False) as tmp_file:\n",
        "            tmp_file.write(file.read())\n",
        "            file_path = tmp_file.name\n",
        "\n",
        "        if file_path.lower().endswith(('.mp4', '.mov', '.avi')):\n",
        "            audio = AudioSegment.from_file(file_path)\n",
        "            audio_path = file_path + \".wav\"\n",
        "            audio.export(audio_path, format=\"wav\")\n",
        "            os.unlink(file_path)\n",
        "        else:\n",
        "            audio_path = file_path\n",
        "\n",
        "        transcription = transcribe_audio(audio_path, language if language != \"auto\" else None)\n",
        "        os.unlink(audio_path)\n",
        "        return transcription\n",
        "    except Exception as e:\n",
        "        return f\"Error processing file: {str(e)}\"\n",
        "\n",
        "def live_transcribe(audio):\n",
        "    if audio is None:\n",
        "        return \"No audio detected\"\n",
        "\n",
        "    with tempfile.NamedTemporaryFile(suffix=\".wav\", delete=False) as f:\n",
        "        f.write(audio[1])\n",
        "        temp_path = f.name\n",
        "\n",
        "    transcription = transcribe_audio(temp_path)\n",
        "    os.unlink(temp_path)\n",
        "    return transcription\n",
        "\n",
        " # Create Gradio interface\n",
        "with gr.Blocks(title=\"Audio/Video Transcription\", theme=gr.themes.Soft()) as demo:\n",
        "    gr.Markdown(\"\"\"\n",
        "    # ðŸŽ¤ Audio/Video Transcription Tool\n",
        "    Upload an audio/video file or use your microphone for live transcription\n",
        "    \"\"\")\n",
        "\n",
        "    with gr.Tabs():\n",
        "        with gr.Tab(\"File Upload\"):\n",
        "            file_input = gr.File(label=\"Upload Audio or Video File\",\n",
        "                               file_types=[\".mp3\", \".wav\", \".ogg\", \".flac\", \".mp4\", \".mov\", \".avi\"])\n",
        "\n",
        "            language = gr.Dropdown(\n",
        "                label=\"Language (select 'auto' for automatic detection)\",\n",
        "                choices=[\"auto\", \"en\", \"es\", \"fr\", \"de\", \"it\", \"pt\", \"ru\", \"zh\", \"ja\", \"hi\"],\n",
        "                value=\"auto\"\n",
        "            )\n",
        "\n",
        "            file_output = gr.Textbox(label=\"Transcription\", lines=10)\n",
        "            file_button = gr.Button(\"Transcribe\", variant=\"primary\")\n",
        "\n",
        "        with gr.Tab(\"Live Transcription\"):\n",
        "            gr.Markdown(\"Record your voice and transcribe it in real-time\")\n",
        "            # Changed 'source' to 'sources' and provided a list\n",
        "            live_audio = gr.Audio(sources=[\"microphone\"], type=\"filepath\", label=\"Speak now\")\n",
        "            live_output = gr.Textbox(label=\"Transcription\", lines=10)\n",
        "            live_button = gr.Button(\"Transcribe Recording\", variant=\"primary\")\n",
        "\n",
        "    # Set up event handlers\n",
        "    file_button.click(\n",
        "        process_uploaded_file,\n",
        "        inputs=[file_input, language],\n",
        "        outputs=file_output\n",
        "    )\n",
        "\n",
        "    live_button.click(\n",
        "        live_transcribe,\n",
        "        inputs=live_audio,\n",
        "        outputs=live_output\n",
        "    )\n",
        "\n",
        "# Launch the interface\n",
        "demo.launch(debug=True, share=True)"
      ],
      "metadata": {
        "id": "gmFuRXi3eSyh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "cXOqsGLIgsqI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}